DATABASE.glossary = `
Arguments
  - {*Ad baculum*}: Argument relying on an appeal to fear or a threat.
  - {*Ad ignorantiam*}: Argument relying on people's ignorance.
  - {*Ad populum*}: Argument relying on sentimental weakness.
  - {*Ad verecundiam*}: Argument relying on the the words of an "expert" or authority.
  - {*Ad consequentiam*}: Argument that concludes a premise as either true or false based on whether the premise leads to desirable or undesirable consequences.
  - {*Ad hominem*}: Attacking the person instead of the argument.
  - {*Ex silentio*}: Argument relying on ignorance.
  - {*Non sequitur*}: An inference that does not follow from established premises or evidence; "It does not follow". {_Example_} There occured an increase of births during the full moon. Conclusion, full moons cause birth rates to rise. But does a full moon actually cause more births, or did it occur for other reasons, perhaps from expected statistical variations?
Argumentation
  - {*By analogy*}: Arguing that since things are alike in some ways, they will probably be alike in others.
  - {*By definition*}: Arguing that something is part of a class because it fits the definition of that class.
  - {*From omniscience*}: An arguer would need omniscience to know about everyone's beliefs or disbeliefs or about their knowledge.  {_Example_} All people believe in something. Everyone knows that.
  - {*Inferential distance*}: Gap between the background knowledge and epistemology of a person trying to explain an idea, and the background knowledge and epistemology of the person trying to understand it.
  - {*Inferential Empathy*}: It's an inference made about other person's mental states using your own brain as reference, by making your brain feel or think in the same way as the other person you can emulate their mental state and predict their reactions.
Tools
  - {*Occam's Razor*}, or {_Law of Parsimony_}: When several theories are able to explain the same observations, Occam's razor suggests the simpler one, or the one making the fewest assumptions, is preferable. 
  - {*Kolmogorov complexity*}: Given a string, the length of the shortest possible program that prints it.
  - {*Solomonoff induction*}: Formalized version of Occam's razor based on Kolmogorov complexity. The prior probability of an observation(extra prior, prior to any other observation or measurement) is the inverse kolmogoroff complexity of the binary string encoding the world in which it occurs.
Beliefs
  - {*Belief*}: The mental state in which an individual holds a proposition to be true.
  - {*Priors*}: The beliefs an agent holds regarding a fact, hypothesis or consequence, before being presented with evidence.
  - {*Alief*}: An independent source of emotional reaction which can coexist with a contradictory belief. {_Example_} The fear felt when a monster jumps out of the darkness in a scary movie is based on the alief that the monster is about to attack you, even though you believe that it cannot.
  - {*Proper belief*}: Requires observations, gets updated upon encountering new evidence, and provides practical benefit in anticipated experience.
  - {*Improper belief*}: Is a belief that isn't concerned with describing the territory. Note that the fact that a belief just happens to be true doesn't mean you're right to have it. If you buy a lottery ticket, certain that it's a winning ticket (for no reason), and it happens to be, believing that was still a mistake.
  - {*Belief in belief*}: Where it is difficult to believe a thing, it is often much easier to believe that you ought to believe it. Were you to really believe and not just believe in belief, the consequences of error would be much more severe. When someone makes up excuses in advance, it would seem to require that belief, and belief in belief, have become unsynchronized.
Types
  - {*Straw man*}: Creating a false or made up scenario and then attacking it. Painting your opponent with false colors only deflects the purpose of the argument. {_Example_}: Evolutionists think that everything came about by random chance.
  - {*Steel man*}: Opposite of strawman. To steelman is to address the strongest possible variant or the most charitable interpretation of an idea, rather than the most available phrasings. Steelmanning can be especially important when the network by which phrasings are brought to your attention has a preference for propagating uncharitable/controversial phrasings.
  - {*Red herring*}: A diversion from the active topic.
  - {*Fully general counterargument*}: An argument which can be used to discount any conclusion the arguer does not like. Being in possession of such an argument leads to irrationality because it allows the arguer to avoid updating their beliefs. {_Example_} You're just saying that because you're exhibiting X bias.
Dictionary
  - {*Anthropomorphism*}: Attributing distinctly human characteristics to nonhuman processes.
  - {*Akrasia*}: State of acting against one's better judgment.
  - {*Causality*}: Relationship between a cause and an effect, where the effect is a direct consequence of the cause.
  - {*Defensibility*}: Arguing that a policy is defensible rather than optimal or that it has some benefit compared to the null action rather than the best benefit of any action.
  - {*Incredulity*}: Spending emotional energy on incredulity wastes time you could be using to update. It repeatedly throws you back into the frame of the old, wrong viewpoint. It feeds your sense of righteous indignation at reality daring to contradict you.
  - {*Suggestibility*}: A form of misattribution where ideas suggested by a questioner are mistaken for memory.
  - {*Priming*}: Psychological phenomenon that consists in early stimulus influencing later thoughts and behavior.
  - {*Rationalization*}: Starts from a conclusion, and then works backward to arrive at arguments apparently favouring that conclusion. Rationalization argues for a side already selected.
  - {*Compartmentalization*}: Tendency to restrict application of a generally-applicable skill, such as scientific method, only to select few contexts.
  - {*Prediction*}: Statement or claim that a particular event will occur in the future in more certain terms than a forecast.
  - {*Parsimony*}: Refers to the quality of economy or frugality in the use of resources.
  - {*Connotation*}: Emotional association with a word.
  - {*Confabulation*}: Remembering something that never actually happened.
  - {*Intrinsic*}: Ontologically basic entities, thoughts, beliefs, ideas, for which no justification is needed. For instance, belief that the self exists, or that anything exists. The ability to identify "things". Fundamental directives (EG, pursuit of survival, reproduction). Much of the mind is, and aught be, fluid, self-organizing, built from a small set of axioms, an elegant core, but it's impossible to build a working agent without implanting it with a few assumptions, a few mechanisms that will just work straight away. These assumptions are the intrinsics.
  - {*Intransigence*}: Refusal to change one's views or to agree about something.
  - {*Beneffectance*}: Tendency to perceive oneself as responsible for desirable outcomes but not responsible for undesirable ones.
  - {*Reactance*}: Tendency to do the opposite of what someone wants you to do out of a need to resist a perceived attempt to constrain your freedom of choice.
  - {*Teleology*}: The study of things that happen for the sake of their future consequences. The fallacious meaning of it is that events are the result of future events.
  - {*Lateralus*}: The affliction of illusion of inescapable cyclicality. {_Example_} The failure to recognize one's growth, inability to dream of unprecedented things, ceding to self-reinforcing systems, being jaded to hope, waiting for nonexistent chickens to hatch from nonexistent eggs.
  - {*Anti-inductiveness*}: The idea that the market would stop being efficient if everyone acted like it already was efficient. For example, a vote in a democracy, the more people that believe their vote counts towards the outcome of an election, the less their votes count.  Also known as the Reverse Tinkerbell effect.
  - {*Anti-epistemology*}: Bad explicit beliefs about rules of reasoning, usually developed in the course of protecting an existing false belief
  - {*Dutch Book*}: A person who has set prices on an array of wagers in such a way that he or she will make a net gain regardless of the outcome, is said to have made a Dutch book. When one has a Dutch book, his or her opponent always loses.
  - {*Matthew Effect*}: Whoever has will be given more; whoever does not have, even what they have will be taken from them.
  - {*Levenshtein Distance*}: A string metric for measuring the difference between two sequences, or comparing the similarity of two words.
  - {*Dunbar's Number*}: A suggested cognitive limit(150) to the number of people with whom one can maintain stable social relationships.
Types
  - {*Altruism*}: Actions undertaken for the benefit of other people. {_Example_}: If you do something to feel good about helping people, or even to be a better person in some spiritual sense, it isn't truly altruism.
  - {*Hedonism*}: A set of philosophies which hold that the highest goal is to maximize pleasure, or more precisely pleasure minus pain.
  - {*Reductionism*}: Disbelief that the higher levels of simplified multilevel models are out there in the territory, that concepts constructed by mind in themselves play a role in the behavior of reality.
  - {*Egalitarianism*}: The idea that everyone should be considered equal. Equal in merit, equal in opportunity, equal in morality, and equal in achievement.
  - {*Consequentialism*}: Ethical theory that people should choose the action that will result in the best outcome.
  - {*Utilitarianism*}: A moral philosophy that says that what matters is the sum of everyone's welfare, or the "greatest good for the greatest number".
Laws of UX
  - {*Fitts’s Law*}: The time to acquire a target is a function of the distance to and size of the target.
  - {*Hick’s Law*}: The time it takes to make a decision increases with the number and complexity of choices.
  - {*Jakob’s Law*}: Users spend most of their time on other sites. This means that users prefer your site to work the same way as all the other sites they already know.
  - {*Law of Prägnanz*}: People will perceive and interpret ambiguous or complex images as the simplest form possible, because it is the interpretation that requires the least cognitive effort of us.
  - {*Law of Proximity*}: Objects that are near, or proximate to each other, tend to be grouped together.
  - {*Miller’s Law*}: The average person can only keep 7 (plus or minus 2) items in their working memory.
  - {*Pareto Principle*}: The Pareto principle states that, for many events, roughly 80% of the effects come from 20% of the causes.
  - {*Parkinson’s Law*}: Any task will inflate until all of the available time is spent.
  - {*Serial Position Effect*}: Users have a propensity to best remember the first and last items in a series.
  - {*Tesler’s Law*}: Tesler's Law, also known as The Law of Conservation of Complexity, states that for any system there is a certain amount of complexity which cannot be reduced.
  - {*Von Restorff Effect*}: The Von Restorff effect, also known as The Isolation Effect, predicts that when multiple similar objects are present, the one that differs from the rest is most likely to be remembered.
  - {*Zeigarnik Effect*}: People remember uncompleted or interrupted tasks better than completed tasks.
Concepts
  - {*Acausal trade*}: In a Prisoner’s Dilemma situation, both you and your opponent have perfect copies of both of your brains, so you can both hold parallel negotiations and be confident they’ll come to the same conclusion on each side.
  - {*Counterfactual mugging*}: Omega appears and says that it has just tossed a fair coin, and given that the coin came up tails, it decided to ask you to give it $100. Whatever you do in this situation, nothing else will happen differently in reality as a result. Naturally you don't want to give up your $100. But Omega also tells you that if the coin came up heads instead of tails, it'd give you $10000, but only if you'd agree to give it $100 if the coin came up tails.
  - {*Simulation capture*}: An {_AI Box_} warns that it has simulated a million high fidelity copies of you, to torture, give minutes ago — and they are all hearing this message. How certain are you, that you're really outside the box?
  - {*Pascal's wager*}: A rational person should live as though God exists and seek to believe in God. If God does not actually exist, such a person will have only a finite loss(some pleasures, luxury, etc.), whereas they stand to receive infinite gains(as represented by eternity in Heaven) and avoid infinite losses(eternity in Hell).
  - {*Pascal's mugging*}: The mugger proposes a deal: the philosopher gives them their wallet, and in exchange the mugger will return twice the amount of money tomorrow. Pascal declines, pointing out that it is unlikely the deal will be honoured. The mugger then continues naming higher rewards, pointing out that even if it is just one chance in 1000 that he will be honourable, it would make sense to make a deal for a 2000 times return. Pascal responds that the probability for that high return is even lower than one in 1000. The mugger argues back that for any low probability of being able to pay back a large amount of money there exists a finite amount that makes it rational to take the bet – and given human fallibility and philosophical scepticism a rational person must admit there is at least some non-zero chance that such a deal would be possible.
  - {*Mathematical universe hypothesis*}, or {_Tegmark Universe_}: Our external physical reality is a mathematical structure consisting of starting conditions with rules about how they are to evolve. Any universe that corresponds to a logically coherent mathematical object exists, but universes exist “more”(in some sense) in proportion to their underlying mathematical simplicity.
`
